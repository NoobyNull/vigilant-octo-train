---
phase: 02-import-pipeline
plan: 04
type: execute
wave: 2
depends_on: ["02-01", "02-03"]
files_modified:
  - src/core/import/import_queue.h
  - src/core/import/import_queue.cpp
  - src/core/import/import_task.h
autonomous: true

must_haves:
  truths:
    - "Multiple files import in parallel using configurable thread count"
    - "G-code files flow through the same import pipeline as mesh files"
    - "Duplicates are skipped without stopping the batch"
    - "Errors on individual files do not stop the batch"
    - "Batch completion produces a summary with duplicate and error counts"
  artifacts:
    - path: "src/core/import/import_queue.h"
      provides: "Parallel import queue using ThreadPool"
      contains: "ThreadPool"
    - path: "src/core/import/import_task.h"
      provides: "ImportTask supporting both mesh and G-code types with batch summary"
      contains: "ImportType"
  key_links:
    - from: "src/core/import/import_queue.cpp"
      to: "src/core/threading/thread_pool.h"
      via: "ImportQueue owns or references ThreadPool for parallel workers"
      pattern: "ThreadPool"
    - from: "src/core/import/import_queue.cpp"
      to: "src/core/import/file_handler.h"
      via: "processTask calls FileHandler after successful parse"
      pattern: "FileHandler::handleImportedFile"
    - from: "src/core/import/import_queue.cpp"
      to: "src/core/loaders/gcode_loader.h"
      via: "GCodeLoader accessed through LoaderFactory for .gcode files"
      pattern: "GCodeLoader"
---

<objective>
Overhaul ImportQueue from single-worker sequential processing to parallel multi-worker processing using ThreadPool.

Purpose: This is the core pipeline change. Multiple files should import simultaneously using configurable thread count. The pipeline must handle both mesh and G-code file types, apply file handling mode, track duplicates and errors for batch summary, and remain non-blocking.

Output: Parallel ImportQueue using ThreadPool, ImportTask with G-code support, batch summary tracking.
</objective>

<execution_context>
@/home/matthew/.claude/get-shit-done/workflows/execute-plan.md
@/home/matthew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-import-pipeline/02-CONTEXT.md
@.planning/phases/02-import-pipeline/02-RESEARCH.md
@.planning/phases/02-import-pipeline/02-01-SUMMARY.md
@.planning/phases/02-import-pipeline/02-03-SUMMARY.md
@src/core/import/import_queue.h
@src/core/import/import_queue.cpp
@src/core/import/import_task.h
@src/core/threading/thread_pool.h
@src/core/import/file_handler.h
@src/core/loaders/gcode_loader.h
@src/core/config/config.h
@src/core/database/connection_pool.h
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend ImportTask for G-code type and batch summary tracking</name>
  <files>src/core/import/import_task.h</files>
  <action>
**Add import type enum:**
```cpp
enum class ImportType { Mesh, GCode };
```

**Extend ImportTask struct:**
- Add `ImportType importType = ImportType::Mesh` — determined from file extension
- Add `GCodeMetadata gcodeMetadata` — populated when importType is GCode (include gcode_loader.h forward or the metadata struct)
- Add `i64 gcodeId = 0` — database ID for G-code records (parallel to modelId for mesh)

**Add BatchSummary struct:**
```cpp
struct ImportBatchSummary {
    int totalFiles = 0;
    int successCount = 0;
    int failedCount = 0;
    int duplicateCount = 0;
    std::vector<std::string> duplicateNames;  // Names of skipped duplicates
    std::vector<std::pair<std::string, std::string>> errors; // (filename, error message)

    bool hasIssues() const { return failedCount > 0 || duplicateCount > 0; }
};
```

**Update importStageName:**
For `ImportStage::Parsing`, return different text based on type — but since the function only takes stage, leave as-is. The caller can check importType if needed.

**Helper function to determine import type from extension:**
```cpp
inline ImportType importTypeFromExtension(const std::string& ext) {
    if (ext == "gcode" || ext == "nc" || ext == "ngc" || ext == "tap") {
        return ImportType::GCode;
    }
    return ImportType::Mesh;
}
```
  </action>
  <verify>
Build: `cd /data/DW && cmake --build build --target dw 2>&1 | tail -10` — compiles cleanly.
  </verify>
  <done>
ImportTask has ImportType field distinguishing mesh vs G-code. ImportBatchSummary tracks duplicates and errors for end-of-batch reporting. Helper function determines type from extension.
  </done>
</task>

<task type="auto">
  <name>Task 2: Replace single worker with ThreadPool-based parallel import</name>
  <files>
    src/core/import/import_queue.h
    src/core/import/import_queue.cpp
  </files>
  <action>
**ImportQueue header changes (import_queue.h):**

Replace `std::thread m_worker` with:
- `std::unique_ptr<ThreadPool> m_threadPool` — lazily created on first enqueue
- `ImportBatchSummary m_batchSummary` — accumulated during batch
- `std::mutex m_summaryMutex` — protects summary writes from multiple workers
- Add `const ImportBatchSummary& batchSummary() const` — accessor
- Add `using SummaryCallback = std::function<void(const ImportBatchSummary&)>`
- Add `void setOnBatchComplete(SummaryCallback callback)`
- Add `SummaryCallback m_onBatchComplete`

**ImportQueue implementation changes (import_queue.cpp):**

`enqueue(vector<Path>)`:
1. Reset m_batchSummary (under summaryMutex)
2. Determine thread count from Config: `auto tier = Config::instance().getParallelismTier(); size_t count = calculateThreadCount(tier);`
3. Lazy-create ThreadPool if not exists or if idle: `if (!m_threadPool) m_threadPool = std::make_unique<ThreadPool>(count);`
4. Also increase ConnectionPool size if needed — actually, the pool size is fixed at construction. Log a warning if thread count exceeds pool size. For this plan, ensure the pool is created with adequate size (document this as a wiring concern for Application).
5. For each path:
   - Create ImportTask with proper ImportType from extension
   - Increment m_progress.totalFiles
   - Enqueue a lambda to m_threadPool that:
     - Calls processTask(task)
     - Updates progress atomics
     - Under m_summaryMutex, accumulates to m_batchSummary
     - Under m_mutex, pushes completed task to m_completed
6. Set m_progress.active = true
7. Enqueue a final "sentinel" task to the thread pool that:
   - Waits for all previous tasks to complete (use an atomic counter)
   - Sets m_progress.active = false
   - Invokes m_onBatchComplete(m_batchSummary) via MainThreadQueue if available, or directly

**Alternative simpler approach for sentinel:** Use `std::atomic<int> m_remainingTasks`. Each task decrements on completion. When it hits 0, the last-completing worker fires the batch complete callback.

`processTask(ImportTask& task)`:
- Acquire ScopedConnection from m_pool
- Stages 1-3 (Reading, Hashing, Duplicate check): Same as current, but:
  - For G-code ImportType, use GCodeRepository for duplicate check instead of ModelRepository
  - On duplicate: record in batch summary under m_summaryMutex
- Stage 4 (Parsing): Same — LoaderFactory handles both mesh and G-code via GCodeLoader
  - After loading, if importType == GCode AND loader is GCodeLoader, capture metadata: `task.gcodeMetadata = static_cast<GCodeLoader*>(loader.get())->lastMetadata()`
  - Note: LoaderFactory::loadFromBuffer creates a new loader each call, so we need to either modify loadFromBuffer to return metadata, or load differently for G-code. **Recommended approach:** In processTask, when importType is GCode, manually create GCodeLoader, call loadFromBuffer, then grab metadata. Don't go through LoaderFactory for G-code — that avoids the cast problem.
- Stage 5 (Inserting):
  - For Mesh: same as current (ModelRepository::insert)
  - For GCode: use GCodeRepository::insert with metadata fields populated from task.gcodeMetadata. Set task.gcodeId = inserted ID.
- Stage 5.5 (File Handling — NEW):
  - Read file handling mode from Config
  - Call `FileHandler::handleImportedFile(task.sourcePath, mode, libraryDir, error)`
  - If mode is copy/move and successful, update the record's filePath in DB to the new path
  - On error, log warning but do NOT fail the import (file is already in DB)
- Stage 6 (WaitingForThumbnail): Same for mesh. For G-code, still go to WaitingForThumbnail (thumbnail generation can handle it on main thread)

**Error handling per task:**
- On any error, set task.stage = Failed, task.error = message
- Under m_summaryMutex: push (filename, error) to m_batchSummary.errors, increment failedCount
- Continue — do NOT stop other workers

**Cancel behavior:**
- m_cancelRequested checked at start of each task
- On cancel, remaining tasks fail with "Cancelled"

**Important threading considerations:**
- Each worker lambda captures task BY VALUE (moved into the lambda)
- ConnectionPool must have enough connections for all concurrent workers (at least threadCount + 1 for main thread)
- processTask receives task by reference (captured in lambda's local scope)
- Batch summary writes are protected by m_summaryMutex
- m_completed writes are protected by existing m_mutex
- Progress atomics are lock-free as before
  </action>
  <verify>
Build: `cd /data/DW && cmake --build build --target dw 2>&1 | tail -10` — compiles cleanly. Run tests: `cd /data/DW/build && ctest --output-on-failure 2>&1 | tail -20` — all existing tests pass.
  </verify>
  <done>
ImportQueue uses ThreadPool for parallel import. Tasks distributed across N workers (N from Config parallelism tier). G-code files flow through same pipeline with separate metadata extraction and GCodeRepository insertion. FileHandler applies copy/move/leave mode after parse. BatchSummary accumulates duplicates and errors. Batch complete callback fires when all tasks done.
  </done>
</task>

</tasks>

<verification>
1. `cd /data/DW && cmake --build build 2>&1 | grep -i error` — no errors
2. ImportQueue creates ThreadPool on first enqueue
3. Multiple tasks enqueued = multiple workers process simultaneously
4. G-code files go through GCodeLoader, mesh files through existing loaders
5. FileHandler called after successful parse for copy/move
6. BatchSummary populated with duplicate names and error details
7. Batch complete callback fires when all tasks finished
8. All existing tests pass
</verification>

<success_criteria>
- Files import in parallel (thread count matches Config tier)
- G-code files parsed and inserted into gcode_files table with metadata
- Mesh files continue to work exactly as before
- File handling mode (copy/move/leave) applied after successful parse
- Duplicates skipped, recorded in batch summary
- Errors recorded per-file, do not stop batch
- Batch complete callback provides full ImportBatchSummary
</success_criteria>

<output>
After completion, create `.planning/phases/02-import-pipeline/02-04-SUMMARY.md`
</output>
